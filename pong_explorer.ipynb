{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pong Game - Reinforcement Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement learning (RL) is going to be used to adapt the system to self train. RL is a form of semi-supervised learning where an Agent (Algorithm) receives feedback from the Environment (Game), and based on the feedback makes critical decisions to maximum Reward (Scores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some of the theory applied to design the solution:\n",
    "1. State ($s$)- Current situation returned by the environment, this has the current ball and rectangle position\n",
    "2. Reward ($r$) - the immediate return sent back  from the environment to evaluate the last action, reward is one when the rectangle hits the ball\n",
    "3. Policy} ($\\pi$) - the strategy that the agent employs to determine the next action based on the current state, the policy is to maximize the chances of the ball hitting the rectangle\n",
    "3. Action ($a$) - All the possible decisions the model can take, make the rectangle either move right or left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov decision process formally describe an environment for reinforcement learning where the environment is fully observable. Reinforcement Learning Process are formulated through the Markov Decision Process. Markov property states that the future is independent of the past given the present.\n",
    "\n",
    "\\begin{equation}\n",
    "   \\mathbb{P}[S_{t+1}] = \\mathbb{P}[S_{t+1 }  |  S_{1}..., S_{t}]\n",
    "\\end{equation}\n",
    "\n",
    "The state at a time $t+1$ captures all the relevant information from history. Once the state is known, the history can be thrown away - the state is a sufficient statistic for the future. In predicting the price of the future stocks, the previous prices are really irrelevant. Such is an example of the Markov Process because it has Markov property.\n",
    "\n",
    "What does this mean to us? It means at any particular moment, by knowing the state of the rectangle and ball we can make a decision to move the ball right or left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "from env import Pong\n",
    "import numpy as np\n",
    "import pygame, sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Keras library for the neural network\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "#to scale data in the range of 0 and 1\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pong game is a Reinforcement learning problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the pong game for 1000 steps and get the initial data, at each step the action is randomly selected. 1 is for moving left and 0 is for moving right. The reward is 1 for preventing the ball hitting the bottom surface and 0 when the ball goes past the bottom surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The game dynamics"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game-playing agent controls the red bar at the bottom of the screen. The ball moves at a constant speed, and bounces off the edges of the game area (or the red bar) at a constant angle. During the training phase, the rectangle moves randomly at the bottom, and by chance it may hit the ball. The goal of the research is to learn from these experiences when the all hit the rectangle, and repeat them in similar setup. At each point, we can collect 6 values about the game\n",
    "1. action - random action initiated by the system  - whether move right 0, or left 1\n",
    "2. ball_x - the x value of the ball coordinates\n",
    "3. ball_y - the y value of the ball coordinates\n",
    "4. rect_x - the x value of the rectangle coordinates\n",
    "5. rect_y - the y value of the rectangle coordinates\n",
    "6. reward - whenever the rectangle hits the ball, the reward is one, otherwise it is 0\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: An alternative solution is to take the piixel image as state at each stage, and use the pixel image. This is likely to produce better results - the solution on using coordinates is a naive approach that would allow us to bootstrapteh solution quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Pong()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(episode_count):\n",
    "    \n",
    "    #run the game several times and collect teh data\n",
    "    for e in range(episode_count):\n",
    "        numpy_data = env.step(10000) \n",
    "        \n",
    "        #convert numpy to pandas\n",
    "        data = pd.DataFrame(numpy_data, columns=['action', 'ball_x', 'ball_y', 'rect_x', 'rect_y', 'reward'])\n",
    "        #establish the direction of the ball and the rectancle at each data point\n",
    "        data['ball_direx'] = data['ball_x'].diff()\n",
    "        data['ball_direy'] = data['ball_y'].diff()\n",
    "        data['rect_direx'] = data['rect_x'].diff()\n",
    "        #Remove incomplete rows\n",
    "        data = data.dropna(how = 'any')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the game will pop up in another window, please give it some time to finish\n",
    "data = get_data(20)\n",
    "pygame.quit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>ball_x</th>\n",
       "      <th>ball_y</th>\n",
       "      <th>rect_x</th>\n",
       "      <th>rect_y</th>\n",
       "      <th>reward</th>\n",
       "      <th>ball_direx</th>\n",
       "      <th>ball_direy</th>\n",
       "      <th>rect_direx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action  ball_x  ball_y  rect_x  rect_y  reward  ball_direx  ball_direy  \\\n",
       "1     0.0    60.0    60.0   390.0   580.0     0.0         5.0         5.0   \n",
       "2     1.0    65.0    65.0   385.0   580.0     0.0         5.0         5.0   \n",
       "3     0.0    70.0    70.0   380.0   580.0     0.0         5.0         5.0   \n",
       "4     0.0    75.0    75.0   375.0   580.0     0.0         5.0         5.0   \n",
       "5     1.0    80.0    80.0   370.0   580.0     0.0         5.0         5.0   \n",
       "\n",
       "   rect_direx  \n",
       "1        -5.0  \n",
       "2        -5.0  \n",
       "3        -5.0  \n",
       "4        -5.0  \n",
       "5        -5.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the data collected\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>ball_x</th>\n",
       "      <th>ball_y</th>\n",
       "      <th>rect_x</th>\n",
       "      <th>rect_y</th>\n",
       "      <th>reward</th>\n",
       "      <th>ball_direx</th>\n",
       "      <th>ball_direy</th>\n",
       "      <th>rect_direx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>0.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>0.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>1.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>1.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>1.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>1.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>0.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      action  ball_x  ball_y  rect_x  rect_y  reward  ball_direx  ball_direy  \\\n",
       "2532     0.0    75.0   565.0     0.0   580.0     1.0         5.0         5.0   \n",
       "3261     0.0   560.0   565.0   475.0   580.0     1.0         5.0        -5.0   \n",
       "3763     1.0    85.0   565.0     0.0   580.0     1.0        -5.0        -5.0   \n",
       "3779     1.0     5.0   565.0     0.0   580.0     1.0        -5.0        -5.0   \n",
       "3795     1.0    70.0   565.0     0.0   580.0     1.0         5.0        -5.0   \n",
       "3811     0.0   150.0   565.0    60.0   580.0     1.0         5.0        -5.0   \n",
       "3827     0.0   230.0   565.0   140.0   580.0     1.0         5.0        -5.0   \n",
       "3843     0.0   310.0   565.0   220.0   580.0     1.0         5.0        -5.0   \n",
       "3859     0.0   390.0   565.0   300.0   580.0     1.0         5.0        -5.0   \n",
       "3875     1.0   470.0   565.0   380.0   580.0     1.0         5.0        -5.0   \n",
       "3891     1.0   550.0   565.0   460.0   580.0     1.0         5.0        -5.0   \n",
       "4134     1.0   185.0   565.0   175.0   580.0     1.0         5.0         5.0   \n",
       "4847     1.0   590.0   565.0   545.0   580.0     1.0         5.0         5.0   \n",
       "6046     1.0   265.0   565.0   235.0   580.0     1.0         5.0         5.0   \n",
       "7002     0.0   305.0   565.0   300.0   580.0     1.0         5.0         5.0   \n",
       "7958     0.0   345.0   565.0   295.0   580.0     1.0         5.0         5.0   \n",
       "\n",
       "      rect_direx  \n",
       "2532         0.0  \n",
       "3261        -5.0  \n",
       "3763         0.0  \n",
       "3779         0.0  \n",
       "3795         0.0  \n",
       "3811         5.0  \n",
       "3827         5.0  \n",
       "3843         5.0  \n",
       "3859         5.0  \n",
       "3875         5.0  \n",
       "3891         5.0  \n",
       "4134         5.0  \n",
       "4847        -5.0  \n",
       "6046         5.0  \n",
       "7002         5.0  \n",
       "7958         5.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking out when the rectangle hit the ball\n",
    "mask = (data['reward'] == 1)\n",
    "positive_data = data.loc[mask]\n",
    "positive_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case the ball hit the rectable len(positive_data) times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9999 entries, 1 to 9999\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   action      9999 non-null   float64\n",
      " 1   ball_x      9999 non-null   float64\n",
      " 2   ball_y      9999 non-null   float64\n",
      " 3   rect_x      9999 non-null   float64\n",
      " 4   rect_y      9999 non-null   float64\n",
      " 5   reward      9999 non-null   float64\n",
      " 6   ball_direx  9999 non-null   float64\n",
      " 7   ball_direy  9999 non-null   float64\n",
      " 8   rect_direx  9999 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 781.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiment, we need to be able to predict the right action on the rectangle given aset of conditions: the direction of the ball as well as the position relative to the rectangle. We employ the heatmap to find the correlation between the target - action and the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = data.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(40, 300, n=200),\n",
    "    square=True,\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected corr should be as close as possible to 1, against our target action, but most of it is in the rane 0-0.25, so most likely our model won't perform as good. Nevertheless we will continue to illustrate the concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have captured enough experiences, we replay them to learn from them. At this point we train the FFNN algorithm. The keras library in python is used to model the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model():\n",
    "\n",
    "    #The Feed-Forward Neural Network is used\n",
    "    #in training the Keras model for the binary classification if the rectangle \n",
    "    #should move right or left\n",
    "    #add layers to model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(250, activation='relu', input_shape=(7,)))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most of the data is not really useful, it is just the ball and the rectangle moving in their own direction, we shall focus only on points where the ball actually hit the rectangle. We will learn from the experiences of $4$ states before that. $4$ is a random logical number, to say the $4$ last move were responsible for the ball hitting the rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expReplay(data, model):\n",
    "\n",
    "    #The neural network is retrained at this point. Only positive events are considers\n",
    "    #4 steps before the rectangle hit the ball. Those experiences are the one that are used to build the binary classification\n",
    "    #so that the algorithm would remember them\n",
    "\n",
    "    p = 4 #look back parameter\n",
    "    \n",
    "    mini_batch = pd.DataFrame(columns=['action', 'ball_x', 'ball_y', 'rect_x', 'rect_y', 'reward',  'ball_direx', 'ball_direy', 'rect_direx'])\n",
    "    #identify rows when the ball hit the rectangle and 4 events before that and savethem in a mini-batch\n",
    "    for index, row in data.iterrows():\n",
    "        if data.at[index, 'reward'] == 1:\n",
    "            for i in range(p):\n",
    "                v = index + i - p + 1  #index value to look into the past\n",
    "\n",
    "                mini_batch = mini_batch.append({'action' : data.at[v , 'action'],\n",
    "                                                'ball_x' : data.at[v, 'ball_x'],\n",
    "                                                'ball_y' : data.at[v, 'ball_y'],\n",
    "                                                'rect_x' : data.at[v, 'rect_x'],\n",
    "                                                'rect_y' : data.at[v, 'rect_y'],\n",
    "                                                'reward' : data.at[v, 'reward'],\n",
    "                                                'ball_direx' : data.at[v, 'ball_direx'],\n",
    "                                                'ball_direy' : data.at[v, 'ball_direy'],\n",
    "                                                'rect_direx' : data.at[v, 'rect_direx']},\n",
    "                                               ignore_index=True)\n",
    "\n",
    "        #get the features for trainin teh mean batch\n",
    "        X_train = mini_batch[['ball_x', 'ball_y', 'rect_x', 'rect_y', 'ball_direx', 'ball_direy', 'rect_direx']].to_numpy()\n",
    "\n",
    "        #get the target for training the mini batch\n",
    "        y_train = mini_batch['action']\n",
    "\n",
    "    print('training set size = ' + str(len(X_train)))\n",
    "\n",
    "    #just making sure there is something in the mini batch\n",
    "    if len(X_train) > 0:\n",
    "\n",
    "        #standardization\n",
    "        scaler  = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "\n",
    "        #train the model on the mini-batch\n",
    "        model.fit(X_train, y_train, epochs=300, verbose = 1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size = 64\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.6858 - accuracy: 0.5882 - val_loss: 0.7784 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6254 - accuracy: 0.6078 - val_loss: 0.8510 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5856 - accuracy: 0.7255 - val_loss: 0.9203 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5685 - accuracy: 0.7647 - val_loss: 1.0066 - val_accuracy: 0.4615\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5520 - accuracy: 0.7647 - val_loss: 1.0800 - val_accuracy: 0.4615\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5404 - accuracy: 0.7843 - val_loss: 1.1354 - val_accuracy: 0.4615\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5268 - accuracy: 0.7843 - val_loss: 1.1900 - val_accuracy: 0.5385\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5147 - accuracy: 0.7843 - val_loss: 1.2348 - val_accuracy: 0.5385\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5012 - accuracy: 0.7843 - val_loss: 1.2513 - val_accuracy: 0.4615\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4893 - accuracy: 0.8039 - val_loss: 1.2457 - val_accuracy: 0.3846\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4763 - accuracy: 0.8039 - val_loss: 1.2626 - val_accuracy: 0.3846\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4611 - accuracy: 0.8235 - val_loss: 1.3005 - val_accuracy: 0.3846\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4434 - accuracy: 0.8235 - val_loss: 1.3505 - val_accuracy: 0.3846\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4306 - accuracy: 0.8235 - val_loss: 1.3991 - val_accuracy: 0.3846\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4198 - accuracy: 0.8039 - val_loss: 1.4415 - val_accuracy: 0.3846\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4057 - accuracy: 0.8235 - val_loss: 1.4687 - val_accuracy: 0.3077\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3868 - accuracy: 0.8235 - val_loss: 1.4912 - val_accuracy: 0.3846\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3745 - accuracy: 0.8431 - val_loss: 1.5138 - val_accuracy: 0.4615\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3603 - accuracy: 0.8431 - val_loss: 1.5560 - val_accuracy: 0.4615\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3487 - accuracy: 0.8039 - val_loss: 1.6080 - val_accuracy: 0.4615\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3346 - accuracy: 0.8039 - val_loss: 1.6312 - val_accuracy: 0.4615\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3240 - accuracy: 0.8039 - val_loss: 1.6480 - val_accuracy: 0.4615\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3179 - accuracy: 0.8235 - val_loss: 1.6751 - val_accuracy: 0.4615\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3024 - accuracy: 0.8627 - val_loss: 1.7518 - val_accuracy: 0.4615\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2887 - accuracy: 0.8431 - val_loss: 1.8086 - val_accuracy: 0.4615\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2906 - accuracy: 0.8235 - val_loss: 1.8300 - val_accuracy: 0.4615\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2745 - accuracy: 0.8235 - val_loss: 1.7955 - val_accuracy: 0.4615\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2782 - accuracy: 0.8627 - val_loss: 1.8289 - val_accuracy: 0.4615\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2609 - accuracy: 0.8824 - val_loss: 1.9820 - val_accuracy: 0.3077\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2596 - accuracy: 0.8627 - val_loss: 2.0472 - val_accuracy: 0.3846\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2483 - accuracy: 0.8235 - val_loss: 2.0385 - val_accuracy: 0.4615\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2476 - accuracy: 0.8431 - val_loss: 2.0085 - val_accuracy: 0.4615\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2458 - accuracy: 0.8824 - val_loss: 2.0649 - val_accuracy: 0.4615\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2311 - accuracy: 0.8824 - val_loss: 2.1640 - val_accuracy: 0.4615\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2236 - accuracy: 0.8627 - val_loss: 2.1969 - val_accuracy: 0.4615\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2200 - accuracy: 0.8431 - val_loss: 2.2055 - val_accuracy: 0.4615\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2162 - accuracy: 0.8627 - val_loss: 2.1930 - val_accuracy: 0.4615\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2060 - accuracy: 0.9216 - val_loss: 2.1814 - val_accuracy: 0.4615\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2177 - accuracy: 0.8824 - val_loss: 2.2327 - val_accuracy: 0.4615\n",
      "Epoch 40/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2060 - accuracy: 0.9216 - val_loss: 2.2965 - val_accuracy: 0.4615\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1899 - accuracy: 0.8824 - val_loss: 2.3321 - val_accuracy: 0.4615\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1934 - accuracy: 0.8627 - val_loss: 2.3452 - val_accuracy: 0.4615\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1881 - accuracy: 0.9216 - val_loss: 2.3590 - val_accuracy: 0.4615\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1761 - accuracy: 0.9412 - val_loss: 2.4241 - val_accuracy: 0.4615\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1883 - accuracy: 0.9216 - val_loss: 2.4217 - val_accuracy: 0.4615\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1632 - accuracy: 0.9412 - val_loss: 2.3787 - val_accuracy: 0.4615\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1770 - accuracy: 0.9216 - val_loss: 2.4473 - val_accuracy: 0.4615\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1748 - accuracy: 0.9216 - val_loss: 2.5901 - val_accuracy: 0.4615\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1731 - accuracy: 0.9412 - val_loss: 2.6678 - val_accuracy: 0.4615\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1634 - accuracy: 0.9412 - val_loss: 2.6101 - val_accuracy: 0.4615\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1609 - accuracy: 0.9412 - val_loss: 2.6000 - val_accuracy: 0.4615\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1555 - accuracy: 0.9412 - val_loss: 2.6847 - val_accuracy: 0.4615\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1581 - accuracy: 0.9216 - val_loss: 2.7046 - val_accuracy: 0.4615\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1516 - accuracy: 0.9216 - val_loss: 2.6354 - val_accuracy: 0.4615\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1438 - accuracy: 0.9412 - val_loss: 2.6149 - val_accuracy: 0.4615\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1430 - accuracy: 0.9412 - val_loss: 2.6671 - val_accuracy: 0.4615\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1307 - accuracy: 0.9608 - val_loss: 2.7322 - val_accuracy: 0.4615\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1273 - accuracy: 0.9804 - val_loss: 2.7920 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1212 - accuracy: 0.9804 - val_loss: 2.8100 - val_accuracy: 0.4615\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.1259 - accuracy: 0.9804 - val_loss: 2.8366 - val_accuracy: 0.4615\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1122 - accuracy: 0.9608 - val_loss: 2.8580 - val_accuracy: 0.4615\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1139 - accuracy: 0.9608 - val_loss: 2.9428 - val_accuracy: 0.4615\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1204 - accuracy: 0.9804 - val_loss: 3.0520 - val_accuracy: 0.4615\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1205 - accuracy: 0.9412 - val_loss: 2.9719 - val_accuracy: 0.4615\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 2.8900 - val_accuracy: 0.4615\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1134 - accuracy: 0.9608 - val_loss: 2.9345 - val_accuracy: 0.4615\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0988 - accuracy: 0.9608 - val_loss: 3.0398 - val_accuracy: 0.4615\n",
      "Epoch 68/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0992 - accuracy: 0.9804 - val_loss: 3.0794 - val_accuracy: 0.4615\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0930 - accuracy: 0.9804 - val_loss: 3.0679 - val_accuracy: 0.4615\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 3.0785 - val_accuracy: 0.4615\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 3.1599 - val_accuracy: 0.4615\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 3.2143 - val_accuracy: 0.4615\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 3.2599 - val_accuracy: 0.4615\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 3.3088 - val_accuracy: 0.4615\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 3.3452 - val_accuracy: 0.4615\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0703 - accuracy: 0.9804 - val_loss: 3.3491 - val_accuracy: 0.4615\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0663 - accuracy: 0.9804 - val_loss: 3.3675 - val_accuracy: 0.4615\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 3.3927 - val_accuracy: 0.4615\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 3.4294 - val_accuracy: 0.4615\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 3.5073 - val_accuracy: 0.4615\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 3.5210 - val_accuracy: 0.4615\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 3.5217 - val_accuracy: 0.4615\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 3.5586 - val_accuracy: 0.4615\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 3.6197 - val_accuracy: 0.4615\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 3.6720 - val_accuracy: 0.4615\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 3.6821 - val_accuracy: 0.4615\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 3.7011 - val_accuracy: 0.4615\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 3.7232 - val_accuracy: 0.4615\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 3.7849 - val_accuracy: 0.4615\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 3.8526 - val_accuracy: 0.4615\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 3.8753 - val_accuracy: 0.4615\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 3.9079 - val_accuracy: 0.4615\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 3.9546 - val_accuracy: 0.4615\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 4.0115 - val_accuracy: 0.4615\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 4.0738 - val_accuracy: 0.4615\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 4.0879 - val_accuracy: 0.4615\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 4.0925 - val_accuracy: 0.4615\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 4.1281 - val_accuracy: 0.4615\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 4.1615 - val_accuracy: 0.4615\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 4.2040 - val_accuracy: 0.4615\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 4.2076 - val_accuracy: 0.4615\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 4.2419 - val_accuracy: 0.4615\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 4.3419 - val_accuracy: 0.4615\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 4.3741 - val_accuracy: 0.4615\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 4.3656 - val_accuracy: 0.4615\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 4.3878 - val_accuracy: 0.4615\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 4.4392 - val_accuracy: 0.4615\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 4.4842 - val_accuracy: 0.4615\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 4.5232 - val_accuracy: 0.4615\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 4.5403 - val_accuracy: 0.4615\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 4.5739 - val_accuracy: 0.4615\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 4.6361 - val_accuracy: 0.4615\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 4.6928 - val_accuracy: 0.4615\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 4.7144 - val_accuracy: 0.4615\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 4.7240 - val_accuracy: 0.4615\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 4.7731 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 4.8070 - val_accuracy: 0.4615\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 4.8307 - val_accuracy: 0.4615\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 4.8513 - val_accuracy: 0.4615\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 4.8838 - val_accuracy: 0.4615\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 4.9276 - val_accuracy: 0.4615\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 4.9722 - val_accuracy: 0.4615\n",
      "Epoch 123/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 5.0075 - val_accuracy: 0.4615\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 5.0424 - val_accuracy: 0.4615\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 5.0733 - val_accuracy: 0.4615\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 5.1217 - val_accuracy: 0.4615\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 5.1433 - val_accuracy: 0.4615\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 5.1492 - val_accuracy: 0.4615\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 5.1664 - val_accuracy: 0.4615\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 5.1956 - val_accuracy: 0.4615\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 5.2397 - val_accuracy: 0.4615\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 5.2768 - val_accuracy: 0.4615\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 5.3000 - val_accuracy: 0.4615\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 5.3313 - val_accuracy: 0.4615\n",
      "Epoch 135/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 5.3604 - val_accuracy: 0.4615\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 5.3956 - val_accuracy: 0.4615\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 5.4323 - val_accuracy: 0.4615\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.4640 - val_accuracy: 0.4615\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.4800 - val_accuracy: 0.4615\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 5.4884 - val_accuracy: 0.4615\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 5.4976 - val_accuracy: 0.3846\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 5.5164 - val_accuracy: 0.3846\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 5.5393 - val_accuracy: 0.3846\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 5.5690 - val_accuracy: 0.3846\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 5.6003 - val_accuracy: 0.3846\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 5.6254 - val_accuracy: 0.4615\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 5.6435 - val_accuracy: 0.4615\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 5.6584 - val_accuracy: 0.3846\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 5.6747 - val_accuracy: 0.3846\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 5.6891 - val_accuracy: 0.3846\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 5.7006 - val_accuracy: 0.3846\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 5.7203 - val_accuracy: 0.3846\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 5.7490 - val_accuracy: 0.3846\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 5.7716 - val_accuracy: 0.3846\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 5.7880 - val_accuracy: 0.3846\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.8102 - val_accuracy: 0.3846\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.8355 - val_accuracy: 0.3846\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.8574 - val_accuracy: 0.3846\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.8715 - val_accuracy: 0.3846\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.8843 - val_accuracy: 0.3846\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.8978 - val_accuracy: 0.3846\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.9172 - val_accuracy: 0.3846\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.9378 - val_accuracy: 0.3846\n",
      "Epoch 164/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.9559 - val_accuracy: 0.3846\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.9704 - val_accuracy: 0.3846\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.9821 - val_accuracy: 0.3846\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.9983 - val_accuracy: 0.3846\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.0140 - val_accuracy: 0.3846\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.0340 - val_accuracy: 0.3846\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.0549 - val_accuracy: 0.3846\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 6.0673 - val_accuracy: 0.3846\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.0796 - val_accuracy: 0.3846\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.0884 - val_accuracy: 0.3846\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 6.1026 - val_accuracy: 0.3846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 6.1179 - val_accuracy: 0.3846\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 6.1284 - val_accuracy: 0.3846\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.1384 - val_accuracy: 0.3846\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.1527 - val_accuracy: 0.3846\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.1724 - val_accuracy: 0.3846\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.1912 - val_accuracy: 0.3846\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.2075 - val_accuracy: 0.3846\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.2233 - val_accuracy: 0.3846\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.2381 - val_accuracy: 0.3846\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.2546 - val_accuracy: 0.3846\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.2700 - val_accuracy: 0.3846\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.2823 - val_accuracy: 0.3846\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.2960 - val_accuracy: 0.3846\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.3079 - val_accuracy: 0.3846\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.3189 - val_accuracy: 0.3846\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.3287 - val_accuracy: 0.3846\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.3397 - val_accuracy: 0.3846\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.3525 - val_accuracy: 0.3846\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.3672 - val_accuracy: 0.3846\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.3815 - val_accuracy: 0.3846\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.3957 - val_accuracy: 0.3846\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.4074 - val_accuracy: 0.3846\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.4177 - val_accuracy: 0.3846\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.4300 - val_accuracy: 0.3846\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.4410 - val_accuracy: 0.3846\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.4538 - val_accuracy: 0.3846\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.4674 - val_accuracy: 0.3846\n",
      "Epoch 202/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.4825 - val_accuracy: 0.3846\n",
      "Epoch 203/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.4988 - val_accuracy: 0.3846\n",
      "Epoch 204/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.5118 - val_accuracy: 0.3846\n",
      "Epoch 205/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.5243 - val_accuracy: 0.3846\n",
      "Epoch 206/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5366 - val_accuracy: 0.3846\n",
      "Epoch 207/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5482 - val_accuracy: 0.3846\n",
      "Epoch 208/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.5611 - val_accuracy: 0.3846\n",
      "Epoch 209/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.5743 - val_accuracy: 0.3846\n",
      "Epoch 210/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.5857 - val_accuracy: 0.3846\n",
      "Epoch 211/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.5961 - val_accuracy: 0.3846\n",
      "Epoch 212/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.6074 - val_accuracy: 0.3846\n",
      "Epoch 213/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6187 - val_accuracy: 0.3846\n",
      "Epoch 214/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6317 - val_accuracy: 0.3846\n",
      "Epoch 215/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6439 - val_accuracy: 0.3846\n",
      "Epoch 216/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6563 - val_accuracy: 0.3846\n",
      "Epoch 217/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6669 - val_accuracy: 0.3846\n",
      "Epoch 218/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6805 - val_accuracy: 0.3846\n",
      "Epoch 219/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6932 - val_accuracy: 0.3846\n",
      "Epoch 220/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.7027 - val_accuracy: 0.3846\n",
      "Epoch 221/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7133 - val_accuracy: 0.3846\n",
      "Epoch 222/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7256 - val_accuracy: 0.4615\n",
      "Epoch 223/300\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7397 - val_accuracy: 0.3846\n",
      "Epoch 224/300\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7554 - val_accuracy: 0.3846\n",
      "Epoch 225/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7702 - val_accuracy: 0.3846\n",
      "Epoch 226/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7833 - val_accuracy: 0.3846\n",
      "Epoch 227/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7932 - val_accuracy: 0.3846\n",
      "Epoch 228/300\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.7985 - val_accuracy: 0.4615\n",
      "Epoch 229/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.8053 - val_accuracy: 0.4615\n",
      "Epoch 230/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.8149 - val_accuracy: 0.4615\n",
      "Epoch 231/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.8253 - val_accuracy: 0.4615\n",
      "Epoch 232/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.8387 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.8507 - val_accuracy: 0.3846\n",
      "Epoch 234/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.8612 - val_accuracy: 0.3846\n",
      "Epoch 235/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.8717 - val_accuracy: 0.4615\n",
      "Epoch 236/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.8804 - val_accuracy: 0.4615\n",
      "Epoch 237/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.8892 - val_accuracy: 0.4615\n",
      "Epoch 238/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9.8911e-04 - accuracy: 1.0000 - val_loss: 6.9000 - val_accuracy: 0.4615\n",
      "Epoch 239/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9.7641e-04 - accuracy: 1.0000 - val_loss: 6.9131 - val_accuracy: 0.4615\n",
      "Epoch 240/300\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9.5864e-04 - accuracy: 1.0000 - val_loss: 6.9263 - val_accuracy: 0.4615\n",
      "Epoch 241/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 9.6904e-04 - accuracy: 1.0000 - val_loss: 6.9401 - val_accuracy: 0.3846\n",
      "Epoch 242/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 9.4340e-04 - accuracy: 1.0000 - val_loss: 6.9518 - val_accuracy: 0.4615\n",
      "Epoch 243/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9.2817e-04 - accuracy: 1.0000 - val_loss: 6.9635 - val_accuracy: 0.4615\n",
      "Epoch 244/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 9.3944e-04 - accuracy: 1.0000 - val_loss: 6.9745 - val_accuracy: 0.4615\n",
      "Epoch 245/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9.1480e-04 - accuracy: 1.0000 - val_loss: 6.9871 - val_accuracy: 0.4615\n",
      "Epoch 246/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 8.8640e-04 - accuracy: 1.0000 - val_loss: 6.9990 - val_accuracy: 0.4615\n",
      "Epoch 247/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 9.0715e-04 - accuracy: 1.0000 - val_loss: 7.0099 - val_accuracy: 0.4615\n",
      "Epoch 248/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.7108e-04 - accuracy: 1.0000 - val_loss: 7.0188 - val_accuracy: 0.4615\n",
      "Epoch 249/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.5545e-04 - accuracy: 1.0000 - val_loss: 7.0271 - val_accuracy: 0.4615\n",
      "Epoch 250/300\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 8.7094e-04 - accuracy: 1.0000 - val_loss: 7.0372 - val_accuracy: 0.4615\n",
      "Epoch 251/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 8.4921e-04 - accuracy: 1.0000 - val_loss: 7.0494 - val_accuracy: 0.4615\n",
      "Epoch 252/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 8.3852e-04 - accuracy: 1.0000 - val_loss: 7.0612 - val_accuracy: 0.4615\n",
      "Epoch 253/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 8.2967e-04 - accuracy: 1.0000 - val_loss: 7.0735 - val_accuracy: 0.4615\n",
      "Epoch 254/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 8.2746e-04 - accuracy: 1.0000 - val_loss: 7.0827 - val_accuracy: 0.4615\n",
      "Epoch 255/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.1096e-04 - accuracy: 1.0000 - val_loss: 7.0923 - val_accuracy: 0.4615\n",
      "Epoch 256/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.0609e-04 - accuracy: 1.0000 - val_loss: 7.1002 - val_accuracy: 0.4615\n",
      "Epoch 257/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 7.8216e-04 - accuracy: 1.0000 - val_loss: 7.1103 - val_accuracy: 0.4615\n",
      "Epoch 258/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 7.7323e-04 - accuracy: 1.0000 - val_loss: 7.1210 - val_accuracy: 0.4615\n",
      "Epoch 259/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.5601e-04 - accuracy: 1.0000 - val_loss: 7.1313 - val_accuracy: 0.4615\n",
      "Epoch 260/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.4845e-04 - accuracy: 1.0000 - val_loss: 7.1420 - val_accuracy: 0.4615\n",
      "Epoch 261/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 7.4827e-04 - accuracy: 1.0000 - val_loss: 7.1526 - val_accuracy: 0.4615\n",
      "Epoch 262/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 7.3543e-04 - accuracy: 1.0000 - val_loss: 7.1628 - val_accuracy: 0.4615\n",
      "Epoch 263/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 7.2523e-04 - accuracy: 1.0000 - val_loss: 7.1717 - val_accuracy: 0.4615\n",
      "Epoch 264/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 7.1959e-04 - accuracy: 1.0000 - val_loss: 7.1803 - val_accuracy: 0.4615\n",
      "Epoch 265/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.1424e-04 - accuracy: 1.0000 - val_loss: 7.1901 - val_accuracy: 0.4615\n",
      "Epoch 266/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 7.0198e-04 - accuracy: 1.0000 - val_loss: 7.2000 - val_accuracy: 0.4615\n",
      "Epoch 267/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 6.9897e-04 - accuracy: 1.0000 - val_loss: 7.2100 - val_accuracy: 0.4615\n",
      "Epoch 268/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.8896e-04 - accuracy: 1.0000 - val_loss: 7.2183 - val_accuracy: 0.4615\n",
      "Epoch 269/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.8383e-04 - accuracy: 1.0000 - val_loss: 7.2271 - val_accuracy: 0.4615\n",
      "Epoch 270/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.7556e-04 - accuracy: 1.0000 - val_loss: 7.2355 - val_accuracy: 0.4615\n",
      "Epoch 271/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 6.7167e-04 - accuracy: 1.0000 - val_loss: 7.2453 - val_accuracy: 0.4615\n",
      "Epoch 272/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.5914e-04 - accuracy: 1.0000 - val_loss: 7.2544 - val_accuracy: 0.4615\n",
      "Epoch 273/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.5465e-04 - accuracy: 1.0000 - val_loss: 7.2640 - val_accuracy: 0.4615\n",
      "Epoch 274/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 6.4977e-04 - accuracy: 1.0000 - val_loss: 7.2733 - val_accuracy: 0.4615\n",
      "Epoch 275/300\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 6.4617e-04 - accuracy: 1.0000 - val_loss: 7.2824 - val_accuracy: 0.4615\n",
      "Epoch 276/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 6.3631e-04 - accuracy: 1.0000 - val_loss: 7.2915 - val_accuracy: 0.4615\n",
      "Epoch 277/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 6.5189e-04 - accuracy: 1.0000 - val_loss: 7.2996 - val_accuracy: 0.4615\n",
      "Epoch 278/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.3232e-04 - accuracy: 1.0000 - val_loss: 7.3097 - val_accuracy: 0.4615\n",
      "Epoch 279/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 6.2693e-04 - accuracy: 1.0000 - val_loss: 7.3187 - val_accuracy: 0.4615\n",
      "Epoch 280/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 6.1844e-04 - accuracy: 1.0000 - val_loss: 7.3261 - val_accuracy: 0.4615\n",
      "Epoch 281/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.1230e-04 - accuracy: 1.0000 - val_loss: 7.3337 - val_accuracy: 0.4615\n",
      "Epoch 282/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 6.0167e-04 - accuracy: 1.0000 - val_loss: 7.3427 - val_accuracy: 0.4615\n",
      "Epoch 283/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.9742e-04 - accuracy: 1.0000 - val_loss: 7.3512 - val_accuracy: 0.4615\n",
      "Epoch 284/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.9034e-04 - accuracy: 1.0000 - val_loss: 7.3595 - val_accuracy: 0.4615\n",
      "Epoch 285/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.9011e-04 - accuracy: 1.0000 - val_loss: 7.3677 - val_accuracy: 0.4615\n",
      "Epoch 286/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 5.8885e-04 - accuracy: 1.0000 - val_loss: 7.3761 - val_accuracy: 0.4615\n",
      "Epoch 287/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.7297e-04 - accuracy: 1.0000 - val_loss: 7.3846 - val_accuracy: 0.4615\n",
      "Epoch 288/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.7332e-04 - accuracy: 1.0000 - val_loss: 7.3918 - val_accuracy: 0.4615\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 5.6061e-04 - accuracy: 1.0000 - val_loss: 7.3993 - val_accuracy: 0.4615\n",
      "Epoch 290/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.5838e-04 - accuracy: 1.0000 - val_loss: 7.4069 - val_accuracy: 0.4615\n",
      "Epoch 291/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 5.5384e-04 - accuracy: 1.0000 - val_loss: 7.4152 - val_accuracy: 0.4615\n",
      "Epoch 292/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.4724e-04 - accuracy: 1.0000 - val_loss: 7.4237 - val_accuracy: 0.4615\n",
      "Epoch 293/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.4224e-04 - accuracy: 1.0000 - val_loss: 7.4320 - val_accuracy: 0.4615\n",
      "Epoch 294/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.3615e-04 - accuracy: 1.0000 - val_loss: 7.4394 - val_accuracy: 0.4615\n",
      "Epoch 295/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.3661e-04 - accuracy: 1.0000 - val_loss: 7.4468 - val_accuracy: 0.4615\n",
      "Epoch 296/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.2942e-04 - accuracy: 1.0000 - val_loss: 7.4549 - val_accuracy: 0.4615\n",
      "Epoch 297/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5.2134e-04 - accuracy: 1.0000 - val_loss: 7.4618 - val_accuracy: 0.4615\n",
      "Epoch 298/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 5.2782e-04 - accuracy: 1.0000 - val_loss: 7.4680 - val_accuracy: 0.4615\n",
      "Epoch 299/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.2076e-04 - accuracy: 1.0000 - val_loss: 7.4751 - val_accuracy: 0.4615\n",
      "Epoch 300/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 5.1027e-04 - accuracy: 1.0000 - val_loss: 7.4819 - val_accuracy: 0.4615\n"
     ]
    }
   ],
   "source": [
    "expReplay(data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be the first attempt at training the algorithm. As it gets more and more data, it will begin to learn. And instead of guessing the action to take, we become more and more dependent on it. This is controlled by the Epsilon, which is 1 - purely exploratory in the beginning, but should end up at close to zero as we use the algorithm more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just how the first episode and training would go, and the first training run. We can see that the accuracy is pretty high on the training data, but quite bad on evaluation. The rest code can be run in the application itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opportunities for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Capture the pixel as state and use them as vecctore features - these are bound to produce a model most likely to converge than the coordinates used in this experiment\n",
    "2. Use the other models like Convolutional Network as they do better with pixel data\n",
    "3. Try other Deep Neural network frameworks like Tensorflow and Pytorch\n",
    "4. Improve the game dynamics to run more efficiently and without freezing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
